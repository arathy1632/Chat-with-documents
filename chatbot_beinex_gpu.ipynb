{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqp8NyXZnkq"
      },
      "source": [
        "# Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M635AuVJDb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6ef310-d5f6-487e-9d22-1ed2cce6f049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8FPcXjaBZ8pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9415c7d-6c5c-43c8-83f6-d22ccee25be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (3.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: auto_gptq in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.32.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (2.20.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.25.2)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (1.2.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (2.3.0+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.4.3)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.41.2)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (0.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto_gptq) (4.66.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto_gptq) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto_gptq) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto_gptq) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto_gptq) (0.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto_gptq) (3.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto_gptq) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto_gptq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto_gptq) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto_gptq) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto_gptq) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->auto_gptq) (1.3.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers\n",
        "!pip install auto_gptq\n",
        "!pip install -qqq InstructorEmbedding==1.0.1\n",
        "!pip install pypdf\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsFBWFGh5uLq",
        "outputId": "53fd4c6d-01d3-4737-a961-7799b7cb8fdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.8)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JF96i95R2RMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22fe5105-bc75-42d1-f65b-3dc840853e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda:CUDA extension not installed.\n",
            "WARNING:auto_gptq.nn_modules.qlinear.qlinear_cuda_old:CUDA extension not installed.\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain import HuggingFacePipeline, PromptTemplate\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tEweeyeZZyOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81443b8f-9185-472a-fbfa-fdb0a52e715d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/chatbot_data/data'\n",
        "# DATA_PATH = '/content'\n",
        "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
        "\n",
        "# Create vector database\n",
        "def create_vector_db():\n",
        "    loader = DirectoryLoader(DATA_PATH,\n",
        "                             glob='*.pdf',\n",
        "                             loader_cls=PyPDFLoader)\n",
        "\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
        "                                                   chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    # embeddings = HuggingFaceInstructEmbeddings(\n",
        "    # model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        "# )\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                       model_kwargs={'device': DEVICE})\n",
        "\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    db.save_local(DB_FAISS_PATH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_vector_db()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "adVCm3b43qzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df05512-1df1-475c-c155-6dc62cfb4325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "WARNING - Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\n",
            "WARNING:auto_gptq.modeling._base:Exllamav2 kernel is not installed, reset disable_exllamav2 to True. This may because you installed auto_gptq using a pre-build wheel on Windows, in which exllama_kernels are not compiled. To use exllama_kernels to further speedup inference, you can re-install auto_gptq from source.\n",
            "WARNING - CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n",
            "1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n",
            "2. You are using pytorch without CUDA support.\n",
            "3. CUDA and nvcc are not installed in your device.\n",
            "WARNING:auto_gptq.modeling._base:CUDA kernels for auto_gptq are not installed, this will result in very slow inference speed. This may because:\n",
            "1. You disabled CUDA extensions compilation by setting BUILD_CUDA_EXT=0 when install auto_gptq from source.\n",
            "2. You are using pytorch without CUDA support.\n",
            "3. CUDA and nvcc are not installed in your device.\n",
            "WARNING - ignoring unknown parameter in quantize_config.json: quant_method.\n",
            "WARNING:auto_gptq.modeling._base:ignoring unknown parameter in quantize_config.json: quant_method.\n",
            "INFO - The layer lm_head is not quantized.\n",
            "INFO:auto_gptq.modeling._base:The layer lm_head is not quantized.\n",
            "The model 'LlamaGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_name_or_path = \"TechxGenus/Meta-Llama-3-8B-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "import torch\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "# model = AutoGPTQForCausalLM.from_quantized(\n",
        "#     model_name_or_path,\n",
        "#     revision=\"gptq-4bit-128g-actorder_True\",\n",
        "#     model_basename=model_basename,\n",
        "#     use_safetensors=True,\n",
        "#     trust_remote_code=True,\n",
        "#     inject_fused_attention=False,\n",
        "#     device=DEVICE,\n",
        "#     quantize_config=None,\n",
        "# )\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name_or_path,\n",
        "    model_basename=model_basename,\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=DEVICE,\n",
        "    quantize_config=None,\n",
        ")\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    streamer=streamer,\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "giwcD_rS4csU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8492ed02-92b1-4196-d2d9-8f95890a0d38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f3fd6905060>, model_kwargs={'temperature': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F-HujOO9J21s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fa2cc2-e0ef-4e9f-d0a2-adf16eb183d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/drive/MyDrive/chatbot_data/data/Beinex_Website.pdf': 'https://beinex.com/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/BUSINESS INTELLIGENCE.pdf': 'https://beinex.com/business-intelligence',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Competitive Intelligence.pdf': 'https://beinex.com/competitive-intelligence/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex Digital.pdf': 'https://beinex.com/beinex-digital/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/AI & Automation.pdf': 'https://beinex.com/ai-ml-rpa/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Advanced Analytics.pdf': 'https://beinex.com/advanced-analytics/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/About-Beinex.pdf': 'https://beinex.com/about-beinex/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Alteryx APA Platform.pdf': 'https://beinex.com/alteryx-apa-platform/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Alteryx-partner.pdf': 'https://beinex.com/alteryx-partner/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex - Alation.pdf': 'https://beinex.com/beinex-alation/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex - Microsoft Azure.pdf': 'https://beinex.com/beinex-microsoft-azure/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex Amazon Web Services.pdf': 'https://beinex.com/beinex-amazon-web-services/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex Human Resources.pdf': 'https://beinex.com/beinex-human-resources/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex Procurement.pdf': 'https://beinex.com/beinex-procurement/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex -Sales.pdf': 'https://beinex.com/beinex-sales/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex -Salesforce.pdf': 'https://beinex.com/beinex-salesforce/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex-Aurex.pdf': 'https://beinex.com/beinex-aurex/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex-Careers.pdf': 'https://beinex.com/careers',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex-Finance.pdf': 'https://beinex.com/beinex-finance/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Beinex-Training & Absorption Program.pdf': 'https://beinex.com/training-absorption/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Data Governance.pdf': 'https://beinex.com/data-governance/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Modern Cloud Analytics.pdf': 'https://beinex.com/modern-cloud-analytics/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Risk and Audit Analytics.pdf': 'https://beinex.com/risk-and-audit-analytics/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Snowflake.pdf': 'https://beinex.com/snowflake/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Tableau Support Services.pdf': 'https://beinex.com/En/Tableau_Support_Service',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Tableau.pdf': 'https://beinex.com/tableau-partnership-and-consulting-services/',\n",
              " '/content/drive/MyDrive/chatbot_data/data/Tableau-Beinex.pdf': 'https://beinex.com/tableau-beinex/'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "csv_file = r'/content/colab_links.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Create a dictionary to map PDF filenames to URLs from the DataFrame\n",
        "pdf_to_url = df.set_index('pdf')['url'].to_dict()\n",
        "pdf_to_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TGn1ACx4QER4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27be06f-4d41-433a-c733-a465345fb3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "custom_template = \"\"\"Use the following pieces of information to provide a concise and accurate response to the user's question.\n",
        "If you do not have sufficient information to answer, please indicate that you do not know rather than guessing or providing incorrect information.\n",
        "Answers should be brief and relevant, drawing from both the given context and the chat history. If applicable, consider answering questions based on the chat history as well.\n",
        "No need to give unhelpful answer.\n",
        "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
        "# embeddings = HuggingFaceInstructEmbeddings(\n",
        "#     model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        "# )\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                       model_kwargs={'device': DEVICE})\n",
        "DB_FAISS_PATH='/content/vectorstore/db_faiss'\n",
        "# db = FAISS.load_local(DB_FAISS_PATH, embeddings)\n",
        "db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "# def load_llm():\n",
        "#     # Load the locally downloaded model here\n",
        "#     llm = CTransformers(\n",
        "#         model = \"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "#         model_type=\"llama\",\n",
        "#         max_new_tokens = 1024,\n",
        "#         temperature = 0.9\n",
        "#     )\n",
        "#     return llm\n",
        "llm = llm\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    db.as_retriever(search_kwargs={'k': 2}),\n",
        "    return_source_documents=True,\n",
        "    condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PtpcBwPlftVs"
      },
      "outputs": [],
      "source": [
        "#output function\n",
        "def final_result(query):\n",
        "    result = qa_chain({'question': query, 'chat_history': history})\n",
        "    history.append((query, result['answer']))\n",
        "    url=[]\n",
        "    for i in range(0, len(result['source_documents'])):\n",
        "        metadata_dict = result['source_documents'][i].metadata\n",
        "        source_value = metadata_dict['source'].split('\\\\')[-1]\n",
        "        # print(source_value)\n",
        "        if source_value in pdf_to_url:\n",
        "            url.append(pdf_to_url[source_value])\n",
        "    # print(url)\n",
        "    result['url']=url\n",
        "    result['contact']='https://beinex.com/contact-us/'\n",
        "    response = {\n",
        "    'question': result['question'],\n",
        "    'answer': result['answer'],\n",
        "    'For more information': result['url'],\n",
        "    'Contact us': result['contact']\n",
        "    }\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=[]\n",
        "while True:\n",
        "    query = input(\"What's on your mind? (Type 'exit' to end): \")\n",
        "    if query.lower() == \"exit\":\n",
        "        history.clear()\n",
        "        break\n",
        "\n",
        "    res = final_result(query)\n",
        "    print(res)"
      ],
      "metadata": {
        "id": "cBKucJ1IueZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bd903a-daab-469b-e0ca-2a65613d7e2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What's on your mind? (Type 'exit' to end): What is beinex\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Beinex is a company that provides digital transformation services.\n",
            "\n",
            "{'question': 'What is beinex', 'answer': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nBeinex Digital, a part of Beinex Holdings, is a digital transformation entity with a comprehensive \\nsuite of independent products focused on addressing specific business gaps, use cases, and \\nneeds. It incorporates a spectrum of solutions in the domains of:  \\n \\n \\n \\nAurex  \\nDECADES OF DIGITAL TRANSFORMATION IN DAYS  \\nBeinex in Numbers  \\n83% -Productivity surge in case of a govt. Entity  \\n20 -Custom -built enterprise digital products  \\n2500 -Professionals trained  \\n350+  -Clients\\n\\nBEINEX DIGITAL  \\nWhat makes us who we are.  \\nBeinex Digital, a part of Beinex Holdings, is a digital transformation entity with a comprehensive suite \\nof independent products focused on addressing specific business gaps, use cases, and needs. It \\nincorporates a spectrum of solutions related to employee  health and safety, enterprise product \\nmanagement, performance management, and audit & risk management.\\n\\nQuestion: What is beinex\\nHelpful Answer: Beinex is a company that provides digital transformation services.\\n\", 'For more information': ['https://beinex.com/about-beinex/', 'https://beinex.com/beinex-digital/'], 'Contact us': 'https://beinex.com/contact-us/'}\n",
            "What's on your mind? (Type 'exit' to end): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW-HMLrfQEOf"
      },
      "outputs": [],
      "source": [
        "history=[]\n",
        "query=\"What are the services provided by beinex\"\n",
        "result = qa_chain({'question': query, 'chat_history': history})\n",
        "history.append((query, result['answer']))\n",
        "# history\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "SrcHSag4a4D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK13t3mQQEK_",
        "outputId": "1f077d71-b5d5-491e-bce9-0c285e9be311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the services provided by Beinex Digital?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the information given, we can infer that Beinex Digital provides a range of services related to digital transformation, including analytics capabilities, custom-built enterprise digital products, and professional training. However, without more specific information about each service, I cannot provide a definitive list of all the services offered by Beinex Digital.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': {'question': 'What are the services provided by beinex',\n",
              "  'chat_history': [('What are the services provided by beinex',\n",
              "    ' Based on the information provided, here are the services offered by Beinex:\\n\\n1. Advanced Analytics\\n2. AI/ML/RPA\\n3. Risk and Audit Analytics\\n4. Competitive Intelligence\\n5. Data Governance\\n6. Business Intelligence\\n7. Modern Cloud Analytics\\n8. Tableau Support Services\\n9. Digital Transformation (through Beinex Digital)\\n\\nPlease note that this list may not be exhaustive as there could be other services offered by Beinex that are not mentioned in the given text.'),\n",
              "   ({...},\n",
              "    '  Based on the information given, we can infer that Beinex Digital provides a range of services related to digital transformation, including analytics capabilities, custom-built enterprise digital products, and professional training. However, without more specific information about each service, I cannot provide a definitive list of all the services offered by Beinex Digital.')],\n",
              "  'answer': ' Based on the information provided, here are the services offered by Beinex:\\n\\n1. Advanced Analytics\\n2. AI/ML/RPA\\n3. Risk and Audit Analytics\\n4. Competitive Intelligence\\n5. Data Governance\\n6. Business Intelligence\\n7. Modern Cloud Analytics\\n8. Tableau Support Services\\n9. Digital Transformation (through Beinex Digital)\\n\\nPlease note that this list may not be exhaustive as there could be other services offered by Beinex that are not mentioned in the given text.',\n",
              "  'source_documents': [Document(page_content='company has offices in multiple locations worldwide, including UAE,Qatar , KSA ,UK , India and Kenya.\\nBeinex is a consulting company that provides a range of services including advanced analytics, AI/ML/RPA,\\nrisk and audit analytics, competitive intelligence, data governance, business intelligence,modern cloud analytics,\\nand Tableau support services. The company has partnerships with Tableau ,Alteryx ,Aurex.ai ,Amazon Web Se-\\nries ,Snowflake,Alation ,Salesforce and Microsoft Azure.\\nServices', metadata={'source': '/content/drive/MyDrive/chatbot_data/data/Beinex_Website.pdf', 'page': 0}),\n",
              "   Document(page_content='Beinex Digital, a part of Beinex Holdings, is a digital transformation entity with a comprehensive \\nsuite of independent products focused on addressing specific business gaps, use cases, and \\nneeds. It incorporates a spectrum of solutions in the domains of:  \\n \\n \\n \\nAurex  \\nDECADES OF DIGITAL TRANSFORMATION IN DAYS  \\nBeinex in Numbers  \\n83% -Productivity surge in case of a govt. Entity  \\n20 -Custom -built enterprise digital products  \\n2500 -Professionals trained  \\n350+  -Clients', metadata={'source': '/content/drive/MyDrive/chatbot_data/data/About-Beinex.pdf', 'page': 1})]},\n",
              " 'answer': '  Based on the information given, we can infer that Beinex Digital provides a range of services related to digital transformation, including analytics capabilities, custom-built enterprise digital products, and professional training. However, without more specific information about each service, I cannot provide a definitive list of all the services offered by Beinex Digital.',\n",
              " 'For more information': ['https://beinex.com/about-beinex/',\n",
              "  'https://beinex.com/'],\n",
              " 'Contact us': 'https://beinex.com/contact-us/'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "final_result(result)"
      ]
    }
  ]
}